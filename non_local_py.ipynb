{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "non_local.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWBOug/4f7wKyaYm5O+0RN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sai-vaishnavi30/couresera/blob/master/non_local_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLiqMZ4fJ1C1"
      },
      "source": [
        "from keras.layers import Activation, Reshape, Lambda, dot, add,concatenate\n",
        "from keras.layers import Conv1D, Conv2D, Conv3D\n",
        "from keras.layers import MaxPool1D\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def non_local_block(ip, intermediate_dim=None, compression=2,\n",
        "                    mode='embedded', add_residual=True):\n",
        "    \"\"\"\n",
        "    Adds a Non-Local block for self attention to the input tensor.\n",
        "    Input tensor can be or rank 3 (temporal), 4 (spatial) or 5 (spatio-temporal).\n",
        "    Arguments:\n",
        "        ip: input tensor\n",
        "        intermediate_dim: The dimension of the intermediate representation. Can be\n",
        "            `None` or a positive integer greater than 0. If `None`, computes the\n",
        "            intermediate dimension as half of the input channel dimension.\n",
        "        compression: None or positive integer. Compresses the intermediate\n",
        "            representation during the dot products to reduce memory consumption.\n",
        "            Default is set to 2, which states halve the time/space/spatio-time\n",
        "            dimension for the intermediate step. Set to 1 to prevent computation\n",
        "            compression. None or 1 causes no reduction.\n",
        "        mode: Mode of operation. Can be one of `embedded`, `gaussian`, `dot` or\n",
        "            `concatenate`.\n",
        "        add_residual: Boolean value to decide if the residual connection should be\n",
        "            added or not. Default is True for ResNets, and False for Self Attention.\n",
        "    Returns:\n",
        "        a tensor of same shape as input\n",
        "    \"\"\"\n",
        "    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "    ip_shape = K.int_shape(ip)\n",
        "\n",
        "    if mode not in ['gaussian', 'embedded', 'dot', 'concatenate']:\n",
        "        raise ValueError('`mode` must be one of `gaussian`, `embedded`, `dot` or `concatenate`')\n",
        "\n",
        "    if compression is None:\n",
        "        compression = 1\n",
        "\n",
        "    dim1, dim2, dim3 = None, None, None\n",
        "\n",
        "    # check rank and calculate the input shape\n",
        "    if len(ip_shape) == 3:  # temporal / time series data\n",
        "        rank = 3\n",
        "        batchsize, dim1, channels = ip_shape\n",
        "\n",
        "    elif len(ip_shape) == 4:  # spatial / image data\n",
        "        rank = 4\n",
        "\n",
        "        if channel_dim == 1:\n",
        "            batchsize, channels, dim1, dim2 = ip_shape\n",
        "        else:\n",
        "            batchsize, dim1, dim2, channels = ip_shape\n",
        "\n",
        "    elif len(ip_shape) == 5:  # spatio-temporal / Video or Voxel data\n",
        "        rank = 5\n",
        "\n",
        "        if channel_dim == 1:\n",
        "            batchsize, channels, dim1, dim2, dim3 = ip_shape\n",
        "        else:\n",
        "            batchsize, dim1, dim2, dim3, channels = ip_shape\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Input dimension has to be either 3 (temporal), 4 (spatial) or 5 (spatio-temporal)')\n",
        "\n",
        "    # verify correct intermediate dimension specified\n",
        "    if intermediate_dim is None:\n",
        "        intermediate_dim = channels // 2\n",
        "\n",
        "        if intermediate_dim < 1:\n",
        "            intermediate_dim = 1\n",
        "\n",
        "    else:\n",
        "        intermediate_dim = int(intermediate_dim)\n",
        "\n",
        "        if intermediate_dim < 1:\n",
        "            raise ValueError('`intermediate_dim` must be either `None` or positive integer greater than 1.')\n",
        "\n",
        "    if mode == 'gaussian':  # Gaussian instantiation\n",
        "        x1 = Reshape((-1, channels))(ip)  # xi\n",
        "        x2 = Reshape((-1, channels))(ip)  # xj\n",
        "        f = dot([x1, x2], axes=2)\n",
        "        f = Activation('softmax')(f)\n",
        "\n",
        "    elif mode == 'dot':  # Dot instantiation\n",
        "        # theta path\n",
        "        theta = _convND(ip, rank, intermediate_dim)\n",
        "        theta = Reshape((-1, intermediate_dim))(theta)\n",
        "\n",
        "        # phi path\n",
        "        phi = _convND(ip, rank, intermediate_dim)\n",
        "        phi = Reshape((-1, intermediate_dim))(phi)\n",
        "\n",
        "        f = dot([theta, phi], axes=2)\n",
        "\n",
        "        size = K.int_shape(f)\n",
        "\n",
        "        # scale the values to make it size invariant\n",
        "        f = Lambda(lambda z: (1. / float(size[-1])) * z)(f)\n",
        "\n",
        "    elif mode == 'concatenate':  # Concatenation instantiation\n",
        "        raise NotImplementedError('Concatenate model has not been implemented yet')\n",
        "\n",
        "    else:  # Embedded Gaussian instantiation\n",
        "        # theta path\n",
        "        theta = _convND(ip, rank, intermediate_dim)\n",
        "        theta = Reshape((-1, intermediate_dim))(theta)\n",
        "\n",
        "        # phi path\n",
        "        phi = _convND(ip, rank, intermediate_dim)\n",
        "        phi = Reshape((-1, intermediate_dim))(phi)\n",
        "\n",
        "        if compression > 1:\n",
        "            # shielded computation\n",
        "            phi = MaxPool1D(compression)(phi)\n",
        "\n",
        "        f = dot([theta, phi], axes=2)\n",
        "        f = Activation('softmax')(f)\n",
        "\n",
        "    # g path\n",
        "    g = _convND(ip, rank, intermediate_dim)\n",
        "    g = Reshape((-1, intermediate_dim))(g)\n",
        "\n",
        "    if compression > 1 and mode == 'embedded':\n",
        "        # shielded computation\n",
        "        g = MaxPool1D(compression)(g)\n",
        "\n",
        "    # compute output path\n",
        "    y = dot([f, g], axes=[2, 1])\n",
        "\n",
        "    # reshape to input tensor format\n",
        "    if rank == 3:\n",
        "        y = Reshape((dim1, intermediate_dim))(y)\n",
        "    elif rank == 4:\n",
        "        if channel_dim == -1:\n",
        "            y = Reshape((dim1, dim2, intermediate_dim))(y)\n",
        "        else:\n",
        "            y = Reshape((intermediate_dim, dim1, dim2))(y)\n",
        "    else:\n",
        "        if channel_dim == -1:\n",
        "            y = Reshape((dim1, dim2, dim3, intermediate_dim))(y)\n",
        "        else:\n",
        "            y = Reshape((intermediate_dim, dim1, dim2, dim3))(y)\n",
        "\n",
        "    # project filters\n",
        "    y = _convND(y, rank, channels)\n",
        "\n",
        "    # residual connection\n",
        "    if add_residual:\n",
        "        y = concatenate([ip, y],axis=3)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def _convND(ip, rank, channels):\n",
        "    assert rank in [3, 4, 5], \"Rank of input must be 3, 4 or 5\"\n",
        "\n",
        "    if rank == 3:\n",
        "        x = Conv1D(channels, 1, padding='same', use_bias=False, kernel_initializer='he_normal')(ip)\n",
        "    elif rank == 4:\n",
        "        x = Conv2D(channels, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal')(ip)\n",
        "    else:\n",
        "        x = Conv3D(channels, (1, 1, 1), padding='same', use_bias=False, kernel_initializer='he_normal')(ip)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}